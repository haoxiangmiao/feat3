#!/usr/bin/env python
# vim: set filetype=python sw=2 sts=2 et nofoldenable :
# This is a python script.
# If you encounter problemes when executing it on its own, start it with a python interpreter
from __future__ import print_function
import sys
import platform
import os
import re
import subprocess
import socket
import shutil
import time
import datetime
import random
import multiprocessing
import fnmatch
import peewee as pw
from build_system.feat_util import is_found
from build_system.feat_util import get_output
from build_system.feat_util import get_output_utf8

sys.dont_write_bytecode = True

def branch_tested_before(hostname, branch, build_id):
  branch_sha = "".join(get_output("git show-ref --hash origin/" + branch))

  #check every run with matching branch, hostname and build_id
  runs = Run.select().where(Run.hostname == hostname).where(Run.branch == branch).where(Run.build == build_id)
  if runs.count() == 0:
    return False
  #select run with newest date
  run = runs.order_by(Run.endtime.desc()).get()
  #check if git sha matches with current commit sha
  git_output = Message.select().where(Message.runid == run.id, Message.title == "git output")
  for message in git_output:
    if branch_sha in message.body:
      #check if older runs did not fail
      statuses = Message.select().where(Message.runid == run.id,\
          ((Message.status == "failed") | (Message.status == "warning") | (Message.status == "error")))
      if statuses.count() == 0:
      #if no failure occured in last run, return true
        return True

  return False

def run_test(build_id, branch, myDB, extra_opts):
  os.chdir(src_dirname)
  hostname = socket.gethostname()

  if onlynew and branch != "master" and branch != "develop" and branch_tested_before(hostname, branch, build_id):
    return

  if dump_filename != "":
    build_id_writeable = build_id.replace("=", "_")
    build_id_writeable = build_id_writeable.replace("/", "_")
    dump_filename_full = dump_filename+"-"+hostname+"-"+branch+"-"+build_id_writeable
    dump_file = open(dump_filename_full, "w")
  else:
    dump_filename_full = "not set"

  if scratch != "":
    build_dirname = scratch + os.sep + "feat-regression-build"
  else:
    build_dirname = src_dirname + os.sep + "build"

  #create test run in database
  r = Run.create(branch=branch, hostname=hostname, build=build_id, starttime=time.time())
  if note != "":
    r.notes = note
  r.save()
  m = Message.create(runid=r, stage="intern", status="ok", timestamp=time.time(), title="directories", body="Source: " + src_dirname + "\n" + "Build: " + build_dirname + "\n" + "Dumpfile: " + dump_filename_full)
  m.save()

  #prepare build dir
  shutil.rmtree(build_dirname, True)
  time.sleep(5)
  os.mkdir(build_dirname)

  #git pull
  os.chdir(src_dirname)
  git_output = get_output("git gc --auto")
  git_output += get_output("git checkout -f --no-track -B test123" + hostname + " origin/" + branch)
  git_output.append("git HEAD:")
  git_output += get_output("git log HEAD -n1")
  m = Message.create(runid=r, stage="intern", status="ok", timestamp=time.time(), title="git output", body="\n".join(git_output))
  m.save()
  if dump_filename != "":
    dump_file.write("\n" + "\n".join(git_output))
    dump_file.flush()
  os.chdir(build_dirname)

#workaround for network base file system to prevent rebuilding everything in ctest phase
  if is_found("sync"):
    get_output("sync")

######### CONFIGURE #########
  configure_command = src_dirname + os.sep + "configure " + build_id + " " + extra_opts
  configure_output = get_output_utf8(configure_command)
  configure_output = "\n".join(configure_output)
  if "error" in configure_output.lower() or "traceback" in configure_output.lower():
    m = Message.create(runid=r, stage="configure", status="error", timestamp=time.time(), title="output", body=configure_output)
    m.save()
    r.endtime = time.time()
    r.save()
    return
  elif "warning" in configure_output.lower():
    m = Message.create(runid=r, stage="configure", status="warning", timestamp=time.time(), title="output", body=configure_output)
    m.save()
  else:
    m = Message.create(runid=r, stage="configure", status="ok", timestamp=time.time(), title="output", body=configure_output)
    m.save()

  if dump_filename != "":
    dump_file.write("\n" + src_dirname + os.sep + "configure " + build_id + "\n")
    dump_file.write("\n" + configure_output)
    dump_file.flush()

#workaround for network base file system to prevent rebuilding everything in ctest phase
  if is_found("sync"):
    get_output("sync")

######### MAKE ###############
  def process_compiler_output(plain, token, output):
    pattern = re.compile(plain)
    last_idx = 0
    part_name = "unknown file"
    idx = 0
    ninja_build_target_detection = re.compile("\[\d+/\d+\]")
    ninja_build_target_name = re.compile(r"([\w.\-_]+)[\d:()]* " + plain, re.I)

    while idx < len(output):
      #search for building blocks aka all output corresonponding to one build target
      if "Building" in output[idx]:
        last_idx = idx
        part_name = output[idx].split("/")[-1]
        part_name = part_name.split(".o")[0]
        idx += 1
      elif "Linking" in output[idx]:
        last_idx = idx
        part_name = output[idx].split(" ")[-1]
        idx += 1
      # search for ninja -v alike output
      elif ninja_build_target_detection.search(output[idx]):
        last_idx = idx
        idx += 1

      # error/warning in building block
      elif pattern.search(output[idx].lower()):
        detailed_name = re.search(ninja_build_target_name, output[idx])
        if detailed_name:
          part_name = detailed_name.group(1)
        #search for end of block
        iend = len(output)
        for i in range(idx, len(output)):
          if "Building" in output[i] or "Linking" in output[i] or ninja_build_target_detection.search(output[i]):
            iend = i
            break
        idx = iend
        #end of block found, dump corresponding lines to message
        part_output = ""
        for j in range(last_idx, idx):
          part_output += output[j] + "\n"

        m = Message.create(runid=r, stage="build", status=token, timestamp=time.time(), title=part_name, body=part_output)
        m.save()

      else:
        idx += 1

  if "ninja" in build_id:
    ninja_target = " all"
    if not mpi_only:
      ninja_target += " tests"
    make_command = "ninja -v -k 999 -l " + str(max(2, multiprocessing.cpu_count() - 2)) + ninja_target
    make_output = get_output_utf8(make_command)
  else:
    make_command = "make -j 4 -O -k all"
    make_output = get_output_utf8(make_command)
    if not mpi_only:
      make_command = "make -j 4 -O -k tests"
      make_output += get_output_utf8(make_command)

  process_compiler_output("remark:", "warning", make_output)
  process_compiler_output("remark #", "warning", make_output)
  process_compiler_output("warning:", "warning", make_output)
  process_compiler_output("warning #", "warning", make_output)
  process_compiler_output("error:", "error", make_output)
  process_compiler_output("error #", "error", make_output)
  process_compiler_output("recipe for target '.*' failed", "error", make_output)
  if dump_filename != "":
    dump_file.write("\n" + make_command + "\n\n")
    dump_file.write("\n".join(make_output))
    dump_file.flush()

#workaround for network base file system to prevent rebuilding everything in ctest phase
  if is_found("sync"):
    get_output("sync")

######### TEST #####################
  label_flag = ""
  if mpi_only:
    label_flag = "--label-regex mpi"
  else:
    label_flag = " --schedule-random --label-exclude sleep"
  test_command = "ctest " + label_flag + " --output-on-failure --output-log " + dump_filename_full + ".ctest"
  test_output = get_output_utf8(test_command)

  idx = 0
  while idx < len(test_output):
    if ".   Passed" in test_output[idx]:
      test_name = test_output[idx].split(": ")
      test_name = test_name[1].split(" .")
      test_name = test_name[0]
      #suppress verbosive passed test messages
      test_output[idx] = "Test passed successful\n Test output suppressed via run-feat-dash, to keep the database memory footprint small."
      m = Message.create(runid=r, stage="test", status="passed", timestamp=time.time(), title=test_name, body=test_output[idx])
      m.save()
      idx += 1

    elif "***Failed" in test_output[idx] or "***Not Run" in test_output[idx]:
      # read out current test name
      test_name = test_output[idx].split(": ")
      test_name = test_name[1].split(" .")
      test_name = test_name[0]

      #search for last line corresponding to current failed test
      test_end = len(test_output)
      for i in range(idx, len(test_output)):
        if "Start" in test_output[i]:
          test_end = i
          break
      #gather all output lines of current failed test
      part_output = ""
      for i in range(idx, test_end):
        part_output += test_output[i] + "\n"

      m = Message.create(runid=r, stage="test", status="failed", timestamp=time.time(), title=test_name, body=part_output)
      m.save()
      idx = test_end

    else:
      idx += 1

  if dump_filename != "":
    dump_file.write("\n" + test_command +"\n\n")
    dump_file.write("\n".join(test_output))
    dump_file.close()

  r.endtime = time.time()
  r.save()



################## MAIN ######################
#TODO help, ? und nicht in sys.argv[0] suchen
# output help screen
if len(sys.argv) != 1 and ("help" in " ".join(sys.argv) or "?" in " ".join(sys.argv)):
  print ("This python scripts starts regression tests and submits them to a cdash server")
  print ("Options:")
  print ("dump=absolute_path")
  print ("  dump complete make/ctest output into file given with absolute path, the filename is extended by run specific identifiers.")
  print ("sqlhost=hostname")
  print ("  set hostname as server that runs the sql daemon.")
  print ("sqlport=port")
  print ("  setup port of sql server.")
  print ("scratch=dir")
  print ("  set scratch directory for build files.")
  print ("note=text")
  print ("  set note for all runs.")
  print ("nothirdparty")
  print ("  do not use thirdparty libraries at all.")
  print ("download3party")
  print ("  delete third party zip files and trigger new download")
  print ("nomemcheck")
  print ("  do not use memory checking tools at all.")
  print ("novalgrind")
  print ("  do not use valgrind.")
  print ("nocudamemcheck")
  print ("  do not use cudamemcheck.")
  print ("intel_system_host_compiler=binary")
  print ("  use binary as host compiler for intel icc.")
  print ("clang_system_host_compiler=toolchain")
  print ("  use toolchain folder as host compiler for clang.")
  print ("cuda_host_compiler=binary")
  print ("  use binary as host compiler for nvcc.")
  print ("onlynew")
  print ("  execute runs only if it was not tested before - develop and master will always be tested.")
  print ("cuda_arch=sm_20")
  print ("  use user defined cuda arch.")
  print ("nomkl")
  print ("  do not use mkl")
  print ("unroll_banded")
  print ("  unroll banded matrix kernels")
  print ("lto")
  print ("  use link time optimisation for intel and gcc")
  sys.exit();

dump_filename = ""
scratch = ""
sqlhost = "augias"
sqlport = 3306
note = ""
nothirdparty = False
download3party = False
novalgrind = False
nocudamemcheck = False
nomkl = False
unroll_banded = False
intel_system_host_compiler = ""
clang_system_host_compiler = ""
cuda_host_compiler = ""
onlynew = False
cuda_arch = "sm_20"
lto = ""
mpi_only = False

for i in range(1, len(sys.argv)):
  if sys.argv[i].startswith("dump="):
    dump_filename = sys.argv[i].replace("dump=", "", 1)
  if sys.argv[i].startswith("sqlhost="):
    sqlhost = sys.argv[i].replace("sqlhost=", "", 1)
  if sys.argv[i].startswith("sqlport="):
    sqlport = int(sys.argv[i].replace("sqlport=", "", 1))
  if sys.argv[i].startswith("scratch="):
    scratch = sys.argv[i].replace("scratch=", "", 1)
  if sys.argv[i].startswith("note="):
    note = sys.argv[i].replace("note=", "", 1)
  if sys.argv[i].startswith("nothirdparty"):
    nothirdparty = True
  if sys.argv[i].startswith("download3party"):
    download3party = True
  if sys.argv[i].startswith("nomemcheck"):
    novalgrind = True
    nocudamemcheck = True
  if sys.argv[i].startswith("novalgrind"):
    novalgrind = True
  if sys.argv[i].startswith("nocudamemcheck"):
    nocudamemcheck = True
  if sys.argv[i].startswith("nomkl"):
    nomkl = True
  if sys.argv[i].startswith("intel_system_host_compiler="):
    intel_system_host_compiler = " --system_host_compiler=" + sys.argv[i].replace("intel_system_host_compiler=", "", 1) + " "
  if sys.argv[i].startswith("clang_system_host_compiler="):
    clang_system_host_compiler = " --system_host_compiler=" + sys.argv[i].replace("clang_system_host_compiler=", "", 1) + " "
  if sys.argv[i].startswith("cuda_host_compiler="):
    cuda_host_compiler = sys.argv[i].replace("cuda_host_compiler=", "", 1)
  if sys.argv[i].startswith("onlynew"):
    onlynew = True
  if sys.argv[i].startswith("cuda_arch="):
    cuda_arch = sys.argv[i].replace("cuda_arch=", "", 1)
  if sys.argv[i].startswith("unroll_banded"):
    unroll_banded = True
  if sys.argv[i].startswith("lto"):
    lto = "-lto"
  if sys.argv[i].startswith("mpi_only"):
    mpi_only = True


src_dirname = os.path.abspath(os.path.dirname(sys.argv[0]))
myDB = pw.MySQLDatabase("feastdash", host=sqlhost, port=sqlport, user="feastdash", passwd="feastdash", threadlocals=True)
myDB.connect()

class MySQLModel(pw.Model):
  """A base model that will use our MySQL database"""
  class Meta:
    database = myDB

class User(MySQLModel):
  username = pw.CharField()

class BranchQueue(MySQLModel):
  branch = pw.CharField()
  status = pw.IntegerField()

class Run(MySQLModel):
  branch = pw.CharField()
  hostname = pw.CharField()
  build = pw.CharField()
  starttime = pw.IntegerField()
  endtime = pw.IntegerField()
  notes = pw.TextField()

class Message(MySQLModel):
  runid = pw.ForeignKeyField(Run, related_name="messages", db_column="runid")
  stage = pw.CharField()
  status = pw.CharField()
  timestamp = pw.IntegerField()
  title = pw.CharField()
  body = pw.TextField()

class Attachment(MySQLModel):
  messageid = pw.ForeignKeyField(Message, related_name="attachments", db_column="messageid")
  name = pw.CharField()
  mimetype = pw.CharField()
  data = pw.BlobField()


if not is_found("cmake"):
  print ("cmake not found! aborting...")
  sys.exit(1)
if not is_found("git"):
  print ("git not found! aborting...")
  sys.exit(1)

src_dirname = os.path.abspath(os.path.dirname(sys.argv[0]))
os.chdir(src_dirname)
# fetch remote branches and create a list of fetched branches
#TODO insert output into database
get_output("git fetch -v -p")
raw_branches = get_output("git branch -a")
raw_branches[:] = [s.strip("* ") for s in raw_branches]

extra_opts = ""
if cuda_host_compiler:
  extra_opts += " --cuda_host_compiler=" + cuda_host_compiler + " "
if is_found ("nvcc"):
  extra_opts += " --cuda_arch=" + cuda_arch + " "
if (unroll_banded):
  extra_opts += " --unroll_banded "


addition = " --eickt "
if is_found ("ninja"):
  addition += "-ninja"
else:
  addition += "-unixmake"
if is_found ("nvcc"):
  addition = addition + "-cuda"
if is_found ("ccache"):
  addition = addition + "-ccache"

#delete third party folders to trigger new unpacking, if used
shutil.rmtree(src_dirname+os.sep+"thirdparty"+os.sep+"alglib", True)
shutil.rmtree(src_dirname+os.sep+"thirdparty"+os.sep+"SuiteSparse", True)
shutil.rmtree(src_dirname+os.sep+"thirdparty"+os.sep+"fparser", True)
shutil.rmtree(src_dirname+os.sep+"thirdparty"+os.sep+"parmetis", True)

#delete even the thirdparty package files to trigger new download
if download3party:
  for root, dirs, files in os.walk(src_dirname+os.sep+"thirdparty"):
    for basename in files:
      if fnmatch.fnmatch(basename, "*.zip") or fnmatch.fnmatch(basename, "*.gz") or fnmatch.fnmatch(basename, "*.bz2") or fnmatch.fnmatch(basename, "*.tar"):
        os.remove(os.path.join(root, basename))

if (not nothirdparty):
  addition = addition + "-umfpack"
  addition = addition + "-fparser"
  addition = addition + "-alglib"

if (not nomkl):
  addition = addition + "-mkl"

quadmath_add = ""
gcc_version = get_output("/usr/bin/g++ -dM -E -")
gcc_version = dict(map(lambda x : (x[1], " ".join(x[2:])), [line.split() for line in gcc_version]))
gcc_major = int(gcc_version["__GNUC__"])
gcc_minor = int(gcc_version["__GNUC_MINOR__"])
gcc_minor2 = int(gcc_version["__GNUC_PATCHLEVEL__"])
if gcc_major > 4 or (gcc_major == 4 and gcc_minor > 5):
  quadmath_add = "-quadmath"
parmetis_add = ""
if (not nothirdparty):
  parmetis_add = "-parmetis"

#extract valid branch names
branch_names = []
branches = BranchQueue.select()
for branch in branches:
  if branch.status != 0:
    continue
  #check if branch is present in repository
  branch = branch.branch
  found_branch = False
  for s in raw_branches[:]:
    if "remotes/origin/"+branch in s:
      branch_names.append(branch)

random.shuffle(branch_names)

#move master/develop to the front of the branch queue
if branch_names.count("develop") > 0:
  branch_names.remove("develop")
  branch_names.insert(0, "develop")

if branch_names.count("master") > 0:
  branch_names.remove("master")
  branch_names.insert(0, "master")

#iterate over all branches, that are queued for testing
for branch in branch_names:
  run_test("guess", branch, myDB, extra_opts)

#TODO valgrind/cudamemcheck mit opt ?
  if not mpi_only:
    #if is_found ("valgrind") and is_found ("nvcc") and is_found("g++") and not novalgrind and not nocudamemcheck:
    # run_test("gcc-debug-valgrind-cudamemcheck" + addition + quadmath_add, branch, myDB, extra_opts)
    if is_found ("valgrind") and is_found("g++") and not novalgrind:
      addition_without_cuda = addition.replace("-cuda", "");
      run_test("gcc-debug-valgrind" + addition_without_cuda + quadmath_add, branch, myDB, extra_opts)
    if is_found ("nvcc") and is_found("g++") and not nocudamemcheck:
      run_test("gcc-debug-cudamemcheck" + addition + quadmath_add, branch, myDB, extra_opts)

    if is_found("g++"):
      run_test("gcc-debug" + addition + quadmath_add, branch, myDB, extra_opts)
      run_test("gcc-opt" + lto + addition + quadmath_add, branch, myDB, extra_opts)
    if is_found("clang++"):
      run_test("clang-debug" + addition, branch, myDB, extra_opts + clang_system_host_compiler)
      run_test("clang-opt" + addition, branch, myDB, extra_opts + clang_system_host_compiler)
    if is_found("icpc"):
      run_test("icc-debug" + addition + quadmath_add, branch, myDB, extra_opts + intel_system_host_compiler)
      run_test("icc-opt" + lto + addition + quadmath_add, branch, myDB, extra_opts + intel_system_host_compiler)
    if is_found("pgc++"):
      run_test("pgi-debug" + addition + quadmath_add, branch, myDB, extra_opts)
      run_test("pgi-opt" + addition + quadmath_add, branch, myDB, extra_opts)

  if is_found("mpic++"):
    if is_found("g++"):
      run_test("mpi-gcc-debug" + addition + quadmath_add + parmetis_add, branch, myDB, extra_opts)
      run_test("mpi-gcc-opt" + lto + addition + quadmath_add + parmetis_add, branch, myDB, extra_opts)
    if is_found("clang++"):
      run_test("mpi-clang-debug" + addition + parmetis_add, branch, myDB, extra_opts + clang_system_host_compiler)
      run_test("mpi-clang-opt" + addition + parmetis_add, branch, myDB, extra_opts + clang_system_host_compiler)
    if is_found("icpc"):
      run_test("mpi-icc-debug" + addition + quadmath_add + parmetis_add, branch, myDB, extra_opts + intel_system_host_compiler)
      run_test("mpi-icc-opt" + lto + addition + quadmath_add + parmetis_add, branch, myDB, extra_opts + intel_system_host_compiler)
    if is_found("pgc++"):
      run_test("mpi-pgi-debug" + addition + quadmath_add + parmetis_add, branch, myDB, extra_opts)
      run_test("mpi-pgi-opt" + addition + quadmath_add + parmetis_add, branch, myDB, extra_opts)
